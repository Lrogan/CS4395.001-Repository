{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet is a lexical database of semantic relations between words in more than 200 languages. WordNet links words into semantic relations including synonyms, hyponyms, and meronyms. The synonyms are grouped into synsets with short definitions and usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('exercise.n.01'), Synset('use.n.01'), Synset('exercise.n.03'), Synset('exercise.n.04'), Synset('exercise.n.05'), Synset('exert.v.01'), Synset('practice.v.01'), Synset('exercise.v.03'), Synset('exercise.v.04'), Synset('drill.v.03')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "  #output all synsets for noun: exercise\n",
    "syn = wn.synsets('exercise')\n",
    "print(syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers\n",
    "Nouns seem to all be rooted in entity.n.01. It seems that you start at the top level of *thing* and then go from the mind to the body in terms of hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the activity of exerting your muscles in various ways to keep fit\n",
      "['the doctor recommended regular exercise', 'he did some exercising', 'the physical exertion required by his work kept him fit']\n",
      "[Lemma('exercise.n.01.exercise'), Lemma('exercise.n.01.exercising'), Lemma('exercise.n.01.physical_exercise'), Lemma('exercise.n.01.physical_exertion'), Lemma('exercise.n.01.workout')]\n",
      "[[Synset('entity.n.01'), Synset('abstraction.n.06'), Synset('psychological_feature.n.01'), Synset('event.n.01'), Synset('act.n.02'), Synset('activity.n.01'), Synset('work.n.01'), Synset('labor.n.02'), Synset('effort.n.02'), Synset('exercise.n.01')]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "syn = wn.synsets('exercise')\n",
    "\n",
    "workingSyn = syn[0]\n",
    "\n",
    "print(workingSyn.definition())\n",
    "print(workingSyn.examples())\n",
    "print(workingSyn.lemmas())\n",
    "\n",
    "print(workingSyn.hypernym_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms:  [Synset('effort.n.02')]\n",
      "Hyponyms:  [Synset('arm_exercise.n.01'), Synset('back_exercise.n.01'), Synset('bodybuilding.n.01'), Synset('calisthenics.n.02'), Synset('cardiopulmonary_exercise.n.01'), Synset('gymnastic_exercise.n.01'), Synset('isometrics.n.01'), Synset('isotonic_exercise.n.01'), Synset('kegel_exercises.n.01'), Synset('kick_up.n.01'), Synset('leg_exercise.n.01'), Synset('neck_exercise.n.01'), Synset('set.n.03'), Synset('stomach_exercise.n.01'), Synset('stretch.n.04'), Synset('yoga.n.02')]\n",
      "Meronyms:  []\n",
      "Holonyms:  []\n",
      "Antonyms:  []\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "syn = wn.synsets('exercise')\n",
    "\n",
    "workingSyn = syn[0]\n",
    "\n",
    "print(\"Hypernyms: \", workingSyn.hypernyms())\n",
    "print(\"Hyponyms: \", workingSyn.hyponyms())\n",
    "print(\"Meronyms: \", workingSyn.member_meronyms())\n",
    "print(\"Holonyms: \", workingSyn.member_holonyms())\n",
    "print(\"Antonyms: \", workingSyn.lemmas()[0].antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('working.n.01'), Synset('work.v.01'), Synset('work.v.02'), Synset('work.v.03'), Synset('function.v.01'), Synset('work.v.05'), Synset('exercise.v.03'), Synset('make.v.36'), Synset('work.v.08'), Synset('work.v.09'), Synset('work.v.10'), Synset('bring.v.03'), Synset('work.v.12'), Synset('cultivate.v.02'), Synset('work.v.14'), Synset('influence.v.01'), Synset('work.v.16'), Synset('work.v.17'), Synset('work.v.18'), Synset('work.v.19'), Synset('shape.v.02'), Synset('work.v.21'), Synset('knead.v.01'), Synset('exploit.v.01'), Synset('solve.v.01'), Synset('ferment.v.03'), Synset('sour.v.01'), Synset('work.v.27'), Synset('working.s.01'), Synset('working.s.02'), Synset('working.s.03'), Synset('running.s.06'), Synset('working.s.05')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "  #output all synsets for noun: exercise\n",
    "syn = wn.synsets('working')\n",
    "print(syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers\n",
    "For Nouns every noun ended at the root of entity.n.01. However this is not the case for verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exert oneself by doing mental or physical work for a purpose or out of necessity\n",
      "['I will work hard to improve my grades', 'she worked hard for better living conditions for the poor']\n",
      "[Lemma('work.v.01.work')]\n",
      "[[Synset('work.v.01')]]\n"
     ]
    }
   ],
   "source": [
    "workingSyn = syn[1]\n",
    "\n",
    "print(workingSyn.definition())\n",
    "print(workingSyn.examples())\n",
    "print(workingSyn.lemmas())\n",
    "\n",
    "print(workingSyn.hypernym_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.morphy('working', wn.VERB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers\n",
    "It would seem potato and tomato are particularly related. Wu-Palmer returns a .8 which is quite high considering identity is only .2 away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annual', 'native', 'to', 'South', 'America', 'having', 'underground', 'stolons', 'bearing', 'edible', 'starchy', 'tubers;', 'widely', 'cultivated', 'as', 'a', 'garden', 'vegetable;', 'vines', 'are', 'poisonous']\n",
      "Synset('tomato.n.02')\n",
      "Wu-Palmer:  0.8\n",
      "Lesk:  Synset('tomato.n.02')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "potato = wn.synset('potato.n.02')\n",
    "print(potato.definition().split())\n",
    "tomato = wn.synset('tomato.n.02')\n",
    "print(tomato)\n",
    "\n",
    "print(\"Wu-Palmer: \", wn.wup_similarity(potato, tomato))\n",
    "print(\"Lesk: \", lesk(potato.definition().split(), 'tomato'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers\n",
    "These scores help us understand the general mood of the word that we're looking at. This is very helpfull in eventually getting the mood a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('anguish.n.01')\n",
      "<anguish.n.01: PosScore=0.0 NegScore=0.625>\n",
      "Positive score =  0.0\n",
      "Negative score =  0.625\n",
      "Objective score =  0.375\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "angSyn = wn.synsets('anguish')[0]\n",
    "print(angSyn)\n",
    "anguish = swn.senti_synset('anguish.n.01')\n",
    "print(anguish)\n",
    "print(\"Positive score = \", anguish.pos_score())\n",
    "print(\"Negative score = \", anguish.neg_score())\n",
    "print(\"Objective score = \", anguish.obj_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers\n",
    "Collocations are common groups of words that create the phrases we use in everyday conversation. These usually hold more meaning than is present at first glance.\n",
    "\n",
    "<br>\n",
    "\n",
    "With the mutual information we can see that United States has a decently high mutual information, this means that most of the time when you see United it will be followed by States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n",
      "p(United States) =  0.015860349127182045\n",
      "p(United) =  0.0170573566084788\n",
      "p(States) =  0.03301745635910224\n",
      "pmi =  4.815657649820885\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import text4\n",
    "import math\n",
    "\n",
    "text4.collocations()\n",
    "\n",
    "vocab = len(set(text4))\n",
    "text = ' '.join(text4.tokens)\n",
    "\n",
    "hg = text.count('United States')/vocab\n",
    "print(\"p(United States) = \",hg )\n",
    "h = text.count('United')/vocab\n",
    "print(\"p(United) = \", h)\n",
    "g = text.count('States')/vocab\n",
    "print('p(States) = ', g)\n",
    "pmi = math.log2(hg / (h * g))\n",
    "print('pmi = ', pmi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90b2864b0195a5508ac774f00def394741627176797bec63e4b6717effc2fb31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
