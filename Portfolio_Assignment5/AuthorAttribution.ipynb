{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     author                                               text\n",
      "0  HAMILTON  FEDERALIST. No. 1 General Introduction For the...\n",
      "1       JAY  FEDERALIST No. 2 Concerning Dangers from Forei...\n",
      "2       JAY  FEDERALIST No. 3 The Same Subject Continued (C...\n",
      "3       JAY  FEDERALIST No. 4 The Same Subject Continued (C...\n",
      "4       JAY  FEDERALIST No. 5 The Same Subject Continued (C...\n",
      "HAMILTON                49\n",
      "MADISON                 15\n",
      "HAMILTON OR MADISON     11\n",
      "JAY                      5\n",
      "HAMILTON AND MADISON     3\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "df = pd.read_csv('federalist.csv')\n",
    "cat_type = CategoricalDtype(categories=[\"HAMILTON\", \"JAY\", \"HAMILTON AND MADISON\", \"MADISON\", \"HAMILTON OR MADISON\"], ordered=True)\n",
    "df['author'] = df['author'].astype(cat_type)\n",
    "print(df.head())\n",
    "print(df['author'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "vectorization = TfidfVectorizer(stop_words=stops)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     FEDERALIST. No. 1 General Introduction For the...\n",
      "1     FEDERALIST No. 2 Concerning Dangers from Forei...\n",
      "2     FEDERALIST No. 3 The Same Subject Continued (C...\n",
      "3     FEDERALIST No. 4 The Same Subject Continued (C...\n",
      "4     FEDERALIST No. 5 The Same Subject Continued (C...\n",
      "                            ...                        \n",
      "78    FEDERALIST No. 79 The Judiciary Continued From...\n",
      "79    FEDERALIST No. 80 The Powers of the Judiciary ...\n",
      "80    FEDERALIST. No. 81 The Judiciary Continued, an...\n",
      "81    FEDERALIST No. 82 The Judiciary Continued From...\n",
      "82    FEDERALIST No. 83 The Judiciary Continued in R...\n",
      "Name: text, Length: 83, dtype: object\n",
      "0     HAMILTON\n",
      "1          JAY\n",
      "2          JAY\n",
      "3          JAY\n",
      "4          JAY\n",
      "        ...   \n",
      "78    HAMILTON\n",
      "79    HAMILTON\n",
      "80    HAMILTON\n",
      "81    HAMILTON\n",
      "82    HAMILTON\n",
      "Name: author, Length: 83, dtype: category\n",
      "Categories (5, object): ['HAMILTON' < 'JAY' < 'HAMILTON AND MADISON' < 'MADISON' < 'HAMILTON OR MADISON']\n",
      "Training shape:  (66,)\n",
      "Testing shape:  (17,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(df.text)\n",
    "print(df.author)\n",
    "\n",
    "Xdata = df.text\n",
    "Ytarget = df.author\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdata, Ytarget, test_size=.2, train_size=.8, random_state=1234)\n",
    "print(\"Training shape: \", X_train.shape)\n",
    "print(\"Testing shape: \", X_test.shape)\n",
    "\n",
    "#become \"Vector!!!! a mathematical term, a quantity represented by an arrow with Direction and Magnitude!!!\"\n",
    "X_train = vectorization.fit_transform(X_train)\n",
    "X_test = vectorization.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#maksure to run all code before this statement(even the other blocks) it might get pissy otherwise\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "prediction = nb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "#i require more accuracy\n",
    "vectorization = TfidfVectorizer(stop_words=stops, max_features=1000, ngram_range=(1, 2))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdata, Ytarget, test_size=.2, train_size=.8, random_state=1234)\n",
    "\n",
    "#become \"Vector!!!! a mathematical term, a quantity represented by an arrow with Direction and Magnitude!!!\", but this time with a better constraints\n",
    "X_train = vectorization.fit_transform(X_train)\n",
    "X_test = vectorization.transform(X_test)\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "prediction = nb.predict(X_test)\n",
    "\n",
    "#oh took at that increase Poggies\n",
    "print(\"Accuracy: \", accuracy_score(y_test, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Accuracy:  0.5882352941176471\n",
      "(Hopefully) Better Accuracy:  0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#now without bigrams\n",
    "vectorization = TfidfVectorizer(stop_words=stops, max_features=1000)\n",
    "Xtf = vectorization.fit_transform(Xdata)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtf, Ytarget, test_size=.2, train_size=.8, random_state=1234)\n",
    "\n",
    "#out of the box performance\n",
    "LRDefaults = LogisticRegression()\n",
    "\n",
    "#hope for more accuracy by double iteration, and balancing class weight\n",
    "LRAcc = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=200, class_weight='balanced')\n",
    "\n",
    "LRDefaults.fit(X_train, y_train)\n",
    "LRAcc.fit(X_train, y_train)\n",
    "\n",
    "PDefaults = LRDefaults.predict(X_test)\n",
    "PAcc = LRAcc.predict(X_test)\n",
    "\n",
    "#success Pog\n",
    "print(\"Default Accuracy: \", accuracy_score(y_test, PDefaults))\n",
    "print(\"(Hopefully) Better Accuracy: \", accuracy_score(y_test, PAcc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7647058823529411\n",
      "Param Accuracy:  0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#run previous to get the vectorization object and Xtf, as well as the x and y trains and tests\n",
    "classics = MLPClassifier()\n",
    "classics.fit(X_train, y_train)\n",
    "\n",
    "#i was gonna abv it to CP but on second thought maybe thats not a goood idea\n",
    "classicParams = MLPClassifier(max_iter=1000, solver='lbfgs', hidden_layer_sizes=(50, 40, 20))\n",
    "classicParams.fit(X_train, y_train)\n",
    "\n",
    "prediction = classics.predict(X_test)\n",
    "#ha\n",
    "PP = classicParams.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, prediction))\n",
    "print(\"Param Accuracy: \", accuracy_score(y_test, PP))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90b2864b0195a5508ac774f00def394741627176797bec63e4b6717effc2fb31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
